---
title: "chp7 gam"
author: "Wendy Liang"
date: "2/28/2021"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE,error = FALSE,warning = FALSE,fig.align = 'center')
library(ISLR)
```

### 7.3

```{r}
x = -2:2
y = 1 + x + -2 * (x-1)^2 * I(x>1)
plot(x, y)
```


### 7.9

#### a
```{r}
library(MASS)
set.seed(1)
fit <- lm(nox ~ poly(dis, 3), data = Boston)
summary(fit)

dislims <- range(Boston$dis)
dis.grid <- seq(from = dislims[1], to = dislims[2], by = 0.1)
preds <- predict(fit, list(dis = dis.grid))
plot(nox ~ dis, data = Boston, col = "darkgrey")
lines(dis.grid, preds, col = "red", lwd = 2)
```

The polynomial terms are significant.

#### b
```{r}
rss <- rep(NA, 10)
for (i in 1:10) {
    fit <- lm(nox ~ poly(dis, i), data = Boston)
    rss[i] <- sum(fit$residuals^2)
}
plot(1:10, rss, xlab = "Degree", ylab = "RSS", type = "l")
```

It seems that the RSS decreases with the degree of the polynomial, and so is minimum for a polynomial of degree 10.


#### c
```{r}
library(boot)
deltas <- rep(NA, 10)
for (i in 1:10) {
    fit <- glm(nox ~ poly(dis, i), data = Boston)
    deltas[i] <- cv.glm(Boston, fit, K = 10)$delta[1]
}
plot(1:10, deltas, xlab = "Degree", ylab = "Test MSE", type = "l")
```


#### d
```{r}
library(splines)
fit <- lm(nox ~ bs(dis, knots = c(4, 7, 11)), data = Boston)
summary(fit)

pred <- predict(fit, list(dis = dis.grid))
plot(nox ~ dis, data = Boston, col = "darkgrey")
lines(dis.grid, preds, col = "red", lwd = 2)
```

#### e

```{r}
rss <- rep(NA, 16)
for (i in 3:16) {
    fit <- lm(nox ~ bs(dis, df = i), data = Boston)
    rss[i] <- sum(fit$residuals^2)
}
plot(3:16, rss[-c(1, 2)], xlab = "Degrees of freedom", ylab = "RSS", type = "l")
```

#### f

```{r,message=FALSE,error=FALSE,results='hide'}
cv <- rep(NA, 16)
for (i in 3:16) {
    fit <- glm(nox ~ bs(dis, df = i), data = Boston)
    cv[i] <- cv.glm(Boston, fit, K = 10)$delta[1]
}

```

```{r}
plot(3:16, cv[-c(1, 2)], xlab = "Degrees of freedom", ylab = "Test MSE", type = "l")
```

### 10

### a
```{r}
library(leaps)
set.seed(1)
attach(College)
train <- sample(length(Outstate), length(Outstate) / 2)
test <- -train
College.train <- College[train, ]
College.test <- College[test, ]
fit <- regsubsets(Outstate ~ ., data = College.train, nvmax = 17, method = "forward")
fit.summary <- summary(fit)
par(mfrow = c(1, 3))
plot(fit.summary$cp, xlab = "Number of variables", ylab = "Cp", type = "l")
min.cp <- min(fit.summary$cp)
std.cp <- sd(fit.summary$cp)
abline(h = min.cp + 0.2 * std.cp, col = "red", lty = 2)
abline(h = min.cp - 0.2 * std.cp, col = "red", lty = 2)
plot(fit.summary$bic, xlab = "Number of variables", ylab = "BIC", type='l')
min.bic <- min(fit.summary$bic)
std.bic <- sd(fit.summary$bic)
abline(h = min.bic + 0.2 * std.bic, col = "red", lty = 2)
abline(h = min.bic - 0.2 * std.bic, col = "red", lty = 2)
plot(fit.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted R2", type = "l", ylim = c(0.4, 0.84))
max.adjr2 <- max(fit.summary$adjr2)
std.adjr2 <- sd(fit.summary$adjr2)
abline(h = max.adjr2 + 0.2 * std.adjr2, col = "red", lty = 2)
abline(h = max.adjr2 - 0.2 * std.adjr2, col = "red", lty = 2)
```

#### b

```{r}
library(gam)
fit <- gam(Outstate ~ Private + s(Room.Board, df = 2) + s(PhD, df = 2) + s(perc.alumni, df = 2) + s(Expend, df = 5) + s(Grad.Rate, df = 2), data=College.train)
par(mfrow = c(2, 3))
plot(fit, se = T, col = "blue")
```


#### c

```{r}
preds <- predict(fit, College.test)
err <- mean((College.test$Outstate - preds)^2)
err

tss <- mean((College.test$Outstate - mean(College.test$Outstate))^2)
rss <- 1 - err / tss
rss
```

#### d

```{r}
summary(fit)
```




### 11

#### a

```{r}
set.seed(99)
n <- 100
X1 <- rnorm(100)
X2 <- rnorm(100)
eps <- rnorm(1:100, sd = 1)
b_0 <- 0.9
b_1 <- -1.5
b_2 <- 1
Y = b_0 + b_1*X1 + b_2*X2 +eps
plot(Y)
```

#### b

```{r}
b_h1 <- 1
```

#### c

```{r}
a=Y-b_h1 *X1
b_h2=lm(a~X2)$coef [2]
```

#### d

```{r}
a=Y-b_h2 *X2
b_h1=lm(a~X1)$coef [2]
```


#### e 

```{r}
b_hat0 <- rep(0,1000)
b_hat1 <- rep(0,1000)
b_hat2 <- rep(0,1000)
for (i in 1:1000) {
  a <- Y - b_hat1[i]*X1
  b_hat2[i] <- lm(a ~ X2)$coef[2]
  a <- Y - b_hat2[i]*X2
  b_hat1[i] <- lm(a ~ X1)$coef[2]
  b_hat0[i] <- lm(a ~ X1)$coef[1]
}
plot(b_hat0, ylab = "Estimates", type = "l", col = "red", ylim = c(-2,2), xlim = c(0,100))
lines(b_hat1, col = "blue")
lines(b_hat2, col = "green")
```

#### f

```{r}
fit3 <- lm(Y ~ X1 + X2)
plot(b_hat0, ylab = "Estimates", type = "l", col = "red", ylim = c(-2,2), xlim = c(0,100), lwd = 3)
lines(b_hat1, col = "blue", lwd = 3)
lines(b_hat2, col = "green", lwd = 3)
abline(h = coef(fit3)[1], lty = "dashed", col = "brown", lwd = 3)
abline(h = coef(fit3)[2], lty = "dashed", col = "black", lwd = 3)
abline(h = coef(fit3)[3], lty = "dashed", col = "orange", lwd = 3)
```

#### g

```{r}
b <- data.frame(b_hat0, b_hat1, b_hat2)
head(b)
```







